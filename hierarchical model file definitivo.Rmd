---
title: "data cleaning hierarchical"
author: "Ilaria Crippa"
date: "2024-07-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# DATA CLEANING

```{r}
library(bayesplot)
library(ggplot2)
library(GGally)
library(leaps)
library(ISLR)
library(readxl)
library(combinat)
library(mvtnorm)
library(coda)
library(corrplot)
library(dplyr)
library(tidyr)
library(rjags)
library(rstan)
library(R2jags)
library(bbricks)
library(LaplacesDemon)
```


```{r}
data = read_excel('energy efficiency.xlsx', sheet = 1)
data = data[,-10]
y = data$heating.load 
data_X = data[,1:8] 
```


```{r}
X = as.matrix(data_X)
vettore <- matrix(1, nrow = 768, ncol = 1)
X = cbind(vettore,X)
A = X[,c(1,4,7,8,9)] ## non correlati
B = X[,c(2,3,5,6)]  # correlati
q = ncol(A)   ## non correlati
t = ncol(B)    # correlati
X = cbind(A,B)
P = ncol(X)
W <- diag(1,t)# Scale matrix for the Wishart distribution
W = solve(W)
df <- 4
```



# REGRESSION

## Samples beta posterior MCMC 

```{r}
jags_model_string <- function() {
  return("
    model {
      # Likelihood
      for (i in 1:N) {
        y[i] ~ dnorm(mu[i], tau)
        mu[i] <- inprod(X[i,], beta)
      }

      # Priors for non-correlated betas
      for (j in 1:5) {
        beta[j] ~ dnorm(0,0.001)
      }

      # Priors for correlated betas
      beta[6:9] ~ dmnorm(mu_beta[6:9], Tau[6:9, 6:9])

      # Prior for the precision matrix Tau of correlated betas
      Tau[6:9, 6:9] ~ dwish(W[,], df)
      Sigma[6:9, 6:9] <- inverse(Tau[6:9, 6:9])  # Covariance matrix of correlated betas

      # Hyperpriors for the mean and covariance of correlated betas
      for (j in 6:9) {
        mu_beta[j] <- 0
      }

      # Prior for the observation precision
      tau ~ dgamma(0.01, 0.01)
      sigma2 <- 1/tau  # Observation variance
      
    }
  ")
}

################### initiate values

inits <- function() {
  list(
    beta = rnorm(P, 0, 1),
    tau = rgamma(1, 0.1, 0.1)
  )
}

data_jags <- list(N = nrow(X), P = ncol(X), X = X, W = W, df = df)

#########################################################################
## Specify for which parameters we want to perform posterior inference ##
#########################################################################

parameters <- c("beta")


####################################
## Finally, run the jags function ##
####################################


model_string <- jags_model_string()
model <- jags.model(textConnection(model_string), data = data_jags, inits = inits, n.chains = 1)
update(model, 10)  # Burn-in

samples = coda.samples(model, variable.names = parameters , n.iter = 1000)
beta_post = coda.samples(model, variable.names = "beta", n.iter = 1000)

# Stampa il sommario dei risultati
print(summary(beta_post))
```



## Boxplots of beta post 

```{r}
par(mar = c(3,5,1,1))

boxplot(as.matrix(samples), outline = F, ylim = c(-1000,1000), ylab = expression(beta), las = 1)
abline(h = 0, col = "blue", lty = "dashed")
out_lm = summary(lm(y ~ X - 1))
points(out_lm$coefficients[,1], col = "blue", pch = 16)

par(mar = c(3,5,1,1))

boxplot(as.matrix(samples), outline = F, ylim = c(-80,80), ylab = expression(beta), las = 1)
abline(h = 0, col = "blue", lty = "dashed")
out_lm = summary(lm(y ~ X - 1))
points(out_lm$coefficients[,1], col = "blue", pch = 16)
```


# DIAGNOSTICS

## Traceplots

```{r}
beta_post = as.matrix(coda.samples(model, variable.names = parameters, n.iter = 1000))
coda::traceplot(as.mcmc(beta_post))
```


## Autocorrelation plots

```{r}
autocorr.plot(samples[[1]])
```

## Geweke test

```{r}
# Calcolare il test di Geweke per ciascun parametro
geweke_beta <- geweke.diag(as.mcmc(beta_post))

# Estrai i valori z
z_scores_beta <- geweke_beta$z

# Convertire i risultati in data frame per ggplot2
df_beta <- data.frame(Parameter = rep(paste0("Beta[", 1:9, "]"), each = 5000), Z_Score = as.vector(z_scores_beta))


# Combinare i data frame
df_combined <- rbind(df_beta)

# Grafico dei valori z del test di Geweke
ggplot(df_combined, aes(x = Parameter, y = Z_Score)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = c(-1.96, 1.96), linetype = "dashed", color = "red") +
  labs(title = "Geweke Diagnostic Z-Scores",
       x = "Parameter",
       y = "Z-Score") +
  theme_minimal()

```

## Credible intervals

```{r}
post.means = apply(as.mcmc(beta_post)[,1:9],2, mean)
CI = apply(as.mcmc(beta_post)[,1:9], 2, function(x) quantile(x, c(0.025, 0.975)))

posterior_draws = pivot_longer(as.data.frame(as.mcmc(beta_post)[,1:9]), cols = 1:9) %>% 
  arrange(name) %>% 
  mutate(density = "posterior")
head(posterior_draws)
colnames(posterior_draws) = c("parameter", "value", "density")

prior_draws = data.frame(parameter = rep(c("V1", "V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9"), each = 1000),
                         value = rnorm(9 * 1000, 0, 2),
                         density = rep("prior", 9 * 1000))

draws = rbind(posterior_draws, prior_draws)

# Plot the densities
p1 = ggplot(draws, aes(x = value, colour = density, fill = density)) + 
  geom_density(alpha = 0.2) + xlim(c(-50,50)) +
  theme(aspect.ratio = 1) + 
  theme_bw() + 
  scale_fill_manual(values = c("prior" = "darkgreen", "posterior" = "red")) + 
  scale_color_manual(values = c("prior" = "darkgreen", "posterior" = "red")) + 
  facet_wrap(~parameter, scales = "free") + 
  labs(title = "Prior and Posterior Densities of Coefficients",
       x = "Value", y = "Density"); p1
```

# MODEL SELECTION

## Model selection based on slab and priors

```{r}
# Definizione della funzione che restituisce il modello JAGS come stringa
jags_model_string <- function() {
  return("
    model {
      # Likelihood
      for (i in 1:N) {
        y[i] ~ dnorm(mu[i], tau)
        mu[i] <- inprod(X[i,], beta)
      }

      # Priors for non-correlated betas
      for (j in 1:q) {
        beta[j] <- gamma[j] * beta_raw[j]
        beta_raw[j] ~ dnorm(0, 0.1)
      }

      # Priors for correlated betas
      for (j in (q+1):(q+t)) {
        beta[j] <- gamma[j] * beta_raw[j]
      }
      beta_raw[(q+1):(q+t)] ~ dmnorm(mu_beta[(q+1):(q+t)], Tau[1:t, 1:t])

      # Prior for the precision matrix Tau of correlated betas
      Tau[1:t, 1:t] ~ dwish(W[,], df)
      Sigma[1:t, 1:t] <- inverse(Tau[1:t, 1:t])  # Covariance matrix of correlated betas

      # Hyperpriors for the mean and covariance of correlated betas
      for (j in (q+1):(q+t)) {
        mu_beta[j] <- 0
      }

      # Prior for the observation precision
      tau ~ dgamma(0.01, 0.01)
      sigma2 <- 1/tau  # Observation variance
      
      # Priors for gamma
      for (j in 1:P) {
        gamma[j] ~ dbern(w)
      }

      w ~ dbeta(1, 1)
    }
  ")
}


# Dati per JAGS
data_jags <- list(N = nrow(X), P = ncol(X), X = X, y = y, W = W, df = df, q = q, t = t)

# Valori iniziali
inits <- function() {
  list(
    beta_raw = rnorm(P, 0, 1),
    tau = rgamma(1, 0.1, 0.1),
    gamma = rbinom(P, 1, 0.5)  # Inizializzazione variabile
  )
}

# Parametri da monitorare
parameters <- c("beta", "tau", "deviance")

# Compila e esegui il modello JAGS
model_string <- jags_model_string()
model <- jags.model(textConnection(model_string), data = data_jags, inits = inits, n.chains = 1)
update(model, 100)  # Burn-in
samples <- coda.samples(model, variable.names = parameters, n.iter = 1000)

# Stampa il sommario dei risultati
print(summary(samples))

# Estrai i campioni MCMC per gamma
beta_post = as.matrix(coda.samples(model, variable.names = "beta", n.iter = 1000))
gamma_post = as.matrix(coda.samples(model, variable.names = "gamma", n.iter = 1000))

# Calcola la proporzione di inclusione per ciascun predittore
prob_inclusion <- colMeans(gamma_post)

# Nomina le proporzioni con i nomi delle variabili
names(prob_inclusion) <- c("Intercept", colnames(X)[-1])



# Plot delle proporzioni di inclusione
par(mfrow = c(1, 1), mar = c(5, 5, 2, 2))
barplot_heights <- barplot(prob_inclusion, col = "brown3", ylab = expression(hat(p)[j]), space = 0.4, names.arg = rep("", length(prob_inclusion)))

# Aggiungere le etichette verticali
text(x = barplot_heights, y = par("usr")[3] - 0.01, srt = 90, adj = 1, labels = names(prob_inclusion), xpd = TRUE, cex = 0.7)

```

# MODEL WITHOUT WALL AREA AND ORIENTATION

## DATA CLEANING

```{r}
X = as.matrix(data_X)
vettore <- matrix(1, nrow = 768, ncol = 1)
X = cbind(vettore,X)
A = X[,c(1,8,9)] ## non correlati
B = X[,c(2,3,5,6)]  # correlati
q = ncol(A)   ## non correlati
t = ncol(B)    # correlati
X = cbind(A,B)
P = ncol(X)
W <- diag(1,t)# Scale matrix for the Wishart distribution
W = solve(W)
df <- 7
```

## REGRESSION

```{r}
jags_model_string <- function() {
  return("
    model {
      # Likelihood
      for (i in 1:N) {
        y[i] ~ dnorm(mu[i], tau)
        mu[i] <- inprod(X[i,], beta)
      }

      # Priors for non-correlated betas
      for (j in 1:3) {
        beta[j] ~ dnorm(0,0.1)
      }

      # Priors for correlated betas
      beta[4:7] ~ dmnorm(mu_beta[4:7], Tau[4:7, 4:7])

      # Prior for the precision matrix Tau of correlated betas
      Tau[4:7, 4:7] ~ dwish(W[,], df)
      Sigma[4:7, 4:7] <- inverse(Tau[4:7, 4:7])  # Covariance matrix of correlated betas

      # Hyperpriors for the mean and covariance of correlated betas
      for (j in 4:7) {
        mu_beta[j] <- 0
      }

      # Prior for the observation precision
      tau ~ dgamma(0.01, 0.01)
      sigma2 <- 1/tau  # Observation variance
    }
  ")
}

################### initiate values

inits <- function() {
  list(
    beta = rnorm(P, 0, 1),
    tau = rgamma(1, 0.1, 0.1)
  )
}

data_jags <- list(N = nrow(X), P = ncol(X), X = X, W = W, df = df)

#########################################################################
## Specify for which parameters we want to perform posterior inference ##
#########################################################################

parameters <- c("beta","tau")


####################################
## Finally, run the jags function ##
####################################


model_string <- jags_model_string()
model <- jags.model(textConnection(model_string), data = data_jags, inits = inits, n.chains = 1)
update(model, 1000)  # Burn-in

samples = coda.samples(model, variable.names = parameters , n.iter = 1000)
beta_post = coda.samples(model, variable.names = "beta", n.iter = 1000)
tau_post = coda.samples(model, variable.names = "tau", n.iter = 1000)
# Stampa il sommario dei risultati
print(summary(beta_post))
```


## Boxplots of beta post 

```{r}
par(mar = c(3,5,1,1))

boxplot(as.matrix(beta_post), outline = F, ylim = c(-1000,1000), ylab = expression(beta), las = 1)
abline(h = 0, col = "blue", lty = "dashed")
out_lm = summary(lm(y ~ X - 1))
points(out_lm$coefficients[,1], col = "blue", pch = 16)

par(mar = c(3,5,1,1))

boxplot(as.matrix(beta_post), outline = F, ylim = c(-80,80), ylab = expression(beta), las = 1)
abline(h = 0, col = "blue", lty = "dashed")
out_lm = summary(lm(y ~ X - 1))
points(out_lm$coefficients[,1], col = "blue", pch = 16)
```
## Credible intervals

```{r}
post.means = apply(as.mcmc(beta_post)[,1:7],2, mean)
CI = apply(as.mcmc(beta_post)[,1:7], 2, function(x) quantile(x, c(0.025, 0.975)))

posterior_draws = pivot_longer(as.data.frame(as.mcmc(beta_post)[,1:7]), cols = 1:7) %>% 
  arrange(name) %>% 
  mutate(density = "posterior")
head(posterior_draws)
colnames(posterior_draws) = c("parameter", "value", "density")

prior_draws = data.frame(parameter = rep(c("V1", "V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9"), each = 1000),
                         value = rnorm(9 * 1000, 0, 10),
                         density = rep("prior", 9 * 1000))

draws = rbind(posterior_draws, prior_draws)

# Plot the densities
p1 = ggplot(draws, aes(x = value, colour = density, fill = density)) + 
  geom_density(alpha = 0.2) + xlim(c(-50,50)) +
  theme(aspect.ratio = 1) + 
  theme_bw() + 
  scale_fill_manual(values = c("prior" = "darkgreen", "posterior" = "red")) + 
  scale_color_manual(values = c("prior" = "darkgreen", "posterior" = "red")) + 
  facet_wrap(~parameter, scales = "free") + 
  labs(title = "Prior and Posterior Densities of Coefficients",
       x = "Value", y = "Density"); p1
```


# DIAGNOSTICS

## Traceplots

```{r}
beta_post = as.matrix(coda.samples(model, variable.names = "beta", n.iter = 1000))
coda::traceplot(as.mcmc(beta_post))
```

## Autocorrelation plots

```{r}
autocorr.plot(beta_post)
```

## Geweke test

```{r}
# Calcolare il test di Geweke per ciascun parametro
geweke_beta <- geweke.diag(as.mcmc(beta_post))

# Estrai i valori z
z_scores_beta <- geweke_beta$z

# Convertire i risultati in data frame per ggplot2
df_beta <- data.frame(Parameter = rep(paste0("Beta[", 1:7, "]"), each = 5000), Z_Score = as.vector(z_scores_beta))


# Combinare i data frame
df_combined <- rbind(df_beta)

# Grafico dei valori z del test di Geweke
ggplot(df_combined, aes(x = Parameter, y = Z_Score)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = c(-1.96, 1.96), linetype = "dashed", color = "red") +
  labs(title = "Geweke Diagnostic Z-Scores",
       x = "Parameter",
       y = "Z-Score") +
  theme_minimal()

```

## PREDICTIONS

```{r}
library(bayesplot)


# Assuming you have the following objects already:
# post_beta_jags: matrix of posterior samples for coefficients (iterations x predictors)
# post_tau_jags: vector of posterior samples for precision (iterations)
# y: observed values of the dependent variable
# X: design matrix (predictors)

# Number of posterior samples
n_samples <- nrow(samples[[1]])
beta_post = as.matrix(samples[, 1:7])
# Number of observations
n_obs <- length(y)
tau_post = as.matrix(samples[, 8])
# Generate posterior predictive samples
posterior_predictive <- matrix(0, n_samples, n_obs)

for (i in 1:n_samples) {
  # Calculate the mean of the predictive distribution
  y_pred_mean <-   X %*% beta_post[i, ] 
  # Calculate the standard deviation (since precision is the reciprocal of variance)
  y_pred_sd <- sqrt(1 / as.vector(tau_post[i]))
  # Generate predictive samples
  posterior_predictive[i, ] <- rnorm(n_obs, y_pred_mean, y_pred_sd)
}

# Convert observed values to a matrix for compatibility with bayesplot
y_matrix <- matrix(y, ncol = length(y))

# Plot Posterior Predictive Checks
color_scheme_set("blue")
ppc_dens_overlay(y, posterior_predictive)
```



